{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, Ridge, ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "data = pd.read_csv('result3.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['price'] = data['price'].str.replace(r\"[$,]\",\"\",regex=True).astype(np.float32)\n",
    "# data.columns\n",
    "# data=data.drop('Unnamed: 0',axis=1)\n",
    "data.to_csv(\"result4.csv\")\n",
    "print(data.isnull().sum()) #判断每一列存在na的数值的数目\n",
    "# data.columns\n",
    "data=data.drop('bathrooms_text',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理bath数据\n",
    "bath= []\n",
    "for i in range(0,len(data['room_type'])):\n",
    "    if data['room_type'][i]=='Entire home/apt':\n",
    "        if data['bathrooms_text'][i] == '0 baths' or data['bathrooms_text'][i] == 'Half-bath':\n",
    "            bath.append('No full bathroom')\n",
    "        elif data['bathrooms_text'][i] == '1 bath' or data['bathrooms_text'][i] == '1.5 baths':\n",
    "            bath.append('1 bathroom')\n",
    "        elif data['bathrooms_text'][i] == '2 baths' or data['bathrooms_text'][i] == '2.5 baths':\n",
    "            bath.append('2 bathroom')\n",
    "        elif data['bathrooms_text'][i] == '3 baths' or data['bathrooms_text'][i] == '3.5 baths':\n",
    "            bath.append('3 bathroom')\n",
    "        else:\n",
    "            bath.append('4 or more')\n",
    "    elif data['room_type'][i]=='Private room':\n",
    "        if data['bathrooms_text'][i] == '0 baths' or data['bathrooms_text'][i] == '0 shared baths' or data['bathrooms_text'][i] == 'Half-bath' or data['bathrooms_text'][i] == 'Private half-bath' or data['bathrooms_text'][i] =='Shared half-bath':\n",
    "            bath.append('No full bathroom')\n",
    "        elif data['bathrooms_text'][i] == '1 private bath' or data['bathrooms_text'][i] == '1.5 baths':\n",
    "            bath.append('1 private bathroom')\n",
    "        elif data['bathrooms_text'][i] == '1 shared bath' or data['bathrooms_text'][i] == '1 bath' or data['bathrooms_text'][i] == '1.5 baths' or data['bathrooms_text'][i] == '1.5 shared baths':\n",
    "            bath.append('1 share bathroom')\n",
    "        elif data['bathrooms_text'][i] == '2 baths' or data['bathrooms_text'][i] == '2.5 baths' or data['bathrooms_text'][i] == '2 shared baths' or data['bathrooms_text'][i] == '2.5 shared baths':\n",
    "            bath.append('2 bathroom')\n",
    "        elif data['bathrooms_text'][i] == '3 baths' or data['bathrooms_text'][i] == '3.5 baths' or data['bathrooms_text'][i] == '3 shared baths' or data['bathrooms_text'][i] == '3.5 shared baths':\n",
    "            bath.append('3 bathroom')\n",
    "        else:\n",
    "            bath.append('4 or more')\n",
    "    else:\n",
    "        if data['bathrooms_text'][i] == '0 shared baths' or data['bathrooms_text'][i] == 'Shared half-bath':\n",
    "            bath.append('No full bathroom')\n",
    "        elif data['bathrooms_text'][i] == '1 shared bath' or data['bathrooms_text'][i] == '1.5 shared baths':\n",
    "            bath.append('1 bathroom')\n",
    "        elif data['bathrooms_text'][i] == '2 shared baths' or data['bathrooms_text'][i] == '2.5 shared baths':\n",
    "            bath.append('2 bathroom')\n",
    "        elif data['bathrooms_text'][i] == '3 shared baths' or data['bathrooms_text'][i] == '3.5 shared baths':\n",
    "            bath.append('3 bathroom')\n",
    "        else:\n",
    "            bath.append('4 or more')\n",
    "\n",
    "data['bath']=bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv('result4.csv', encoding='utf-8')\n",
    "items = []\n",
    "numbers = []\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    str1 = datas.at[i, 'amenities']\n",
    "    str1 = str1[2:len(str1) - 2]\n",
    "    list = str1.split(\"\\\", \\\"\")\n",
    "    for j in range(len(list)):\n",
    "        if list[j] not in items:\n",
    "            items.append(list[j])\n",
    "            numbers.append([list[j], 0])\n",
    "\n",
    "print(items)\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    str1 = datas.at[i, 'amenities']\n",
    "    str1 = str1[2:len(str1) - 2]\n",
    "    list = str1.split(\"\\\", \\\"\")\n",
    "    for j in range(len(list)):\n",
    "        index = items.index(list[j])\n",
    "        numbers[index][1] += 1\n",
    "\n",
    "numbers = sorted(numbers, key=lambda x: x[1], reverse=True)\n",
    "need = []\n",
    "# max = 10\n",
    "for i in range(75):\n",
    "    print(f'the top {i} is {numbers[i][0]}, it appears {numbers[i][1]} times')\n",
    "    need.append(numbers[i][0])\n",
    "\n",
    "# ===================================================================================\n",
    "\n",
    "# for column in enumerate(need):\n",
    "#     datas[column] = np.zeros(len(datas))\n",
    "for i in range(len(datas)):\n",
    "    str1 = datas.at[i, 'amenities']\n",
    "    str1 = str1[2:len(str1) - 2]\n",
    "    list = str1.split(\"\\\", \\\"\")\n",
    "\n",
    "    for j in range(len(list)):\n",
    "        if list[j] in need:\n",
    "            datas.at[i, list[j]] = 1\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    for column in re:\n",
    "        if str(datas.at[i, column]) == 'nan':\n",
    "            datas.at[i, column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=datas.columns.to_list()\n",
    "ex=['description' ,'neighborhood_overview','host_response_time','host_response_rate','host_acceptance_rate'  ,'first_review','last_review','review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin' ,'review_scores_communication',                     \n",
    "'review_scores_location','review_scores_value', 'reviews_per_month' ]\n",
    "# print(y)\n",
    "re=[item for item in y if item not in ex]\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(data)):\n",
    "#    if str(data.at[i, 'description']) == 'nan':\n",
    "#        data.at[i, 'description'] = 0\n",
    "for i in range(len(data)):\n",
    "    if str(data.at[i, 'neighborhood_overview']) == 'nan':\n",
    "        data.at[i, 'neighborhood_overview'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "data = pd.read_csv('result5.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "#检验是否含有中文字符\n",
    "def is_contains_chinese(strs):\n",
    "    for _char in strs:\n",
    "        if '\\u4e00' <= _char <= '\\u9fa5':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# SnowNLP(data['description'][5]).sentiments\n",
    "# SnowNLP(data['description'][24]).sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理description\n",
    "desc= []\n",
    "for i in range(0,len(data['description'])):\n",
    "    if data['description'][i] == 0:\n",
    "        desc.append(0)\n",
    "    elif is_contains_chinese(data['description'][i]):\n",
    "        desc.append(SnowNLP(data['description'][i]).sentiments)\n",
    "    else:\n",
    "        desc.append((TextBlob(data['description'][i]).sentiment.polarity+1)/2)\n",
    "    \n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理neigh_over\n",
    "neiover= []\n",
    "for i in range(0,len(data['neighborhood_overview'])):\n",
    "    if data['neighborhood_overview'][i] == 0:\n",
    "        neiover.append(0)\n",
    "    elif is_contains_chinese(data['neighborhood_overview'][i]):\n",
    "        neiover.append(SnowNLP(data['neighborhood_overview'][i]).sentiments)\n",
    "    else:\n",
    "        neiover.append((TextBlob(data['neighborhood_overview'][i]).sentiment.polarity+1)/2)\n",
    "    \n",
    "data['neiover']=neiover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理建筑类型数据\n",
    "BuildingType = []\n",
    "for i in range(0,len(data['room_type'])):\n",
    "    if data['room_type'][i]=='Entire home/apt':\n",
    "        if data['property_type'][i] == 'Barn' or data['property_type'][i] == 'Entire loft':\n",
    "            BuildingType.append('Loft')\n",
    "        elif data['property_type'][i] == 'Room in boutique hotel' or data['property_type'][i] == 'Religious building' or data['property_type'][i] == 'Riad' or data['property_type'][i] == 'Castle':\n",
    "            BuildingType.append('Boutique Hotel')\n",
    "        elif data['property_type'][i] == 'Entire townhouse' or data['property_type'][i] == 'Entire villa':\n",
    "            BuildingType.append('Villa')\n",
    "        elif data['property_type'][i] == 'Kezhan':\n",
    "            BuildingType.append('Kezhan')\n",
    "        elif data['property_type'][i] == 'Room in hotel' or data['property_type'][i] == 'Entire guest suite' or data['property_type'][i] == 'Entire guesthouse' or data['property_type'][i] == 'Entire hostel' or data['property_type'][i] == 'Room in aparthotel':\n",
    "            BuildingType.append('Hotel')\n",
    "        elif data['property_type'][i] == 'Entire bed and breakfast' or data['property_type'][i] == 'Entire bungalow' or data['property_type'][i] == 'Entire place' or data['property_type'][i] == 'Entire residential home':\n",
    "            BuildingType.append('House')\n",
    "        elif data['property_type'][i] == 'Entire resort':\n",
    "            BuildingType.append('Resort')\n",
    "        elif data['property_type'][i] == 'Minsu' or data['property_type'][i] == 'Nature lodge' or data['property_type'][i] == 'Floor' or data['property_type'][i] == 'Tiny house':\n",
    "            BuildingType.append('Homestay')\n",
    "        elif data['property_type'][i] == 'Entire cottage' or data['property_type'][i] == 'Ranch' or data['property_type'][i] == 'Farm stay':\n",
    "            BuildingType.append('Agritainment')\n",
    "        elif data['property_type'][i] == 'Entire cabin' or data['property_type'][i] == 'Entire chalet':\n",
    "            BuildingType.append('Cabin')\n",
    "        elif data['property_type'][i] == 'Camper/RV' or data['property_type'][i] == 'Campsite':\n",
    "            BuildingType.append('Campsite')\n",
    "        elif data['property_type'][i] == 'Tent':\n",
    "            BuildingType.append('Tent')\n",
    "        elif data['property_type'][i] == 'Treehouse':\n",
    "            BuildingType.append('Treehouse')\n",
    "        else:\n",
    "            BuildingType.append('Apartment')\n",
    "\n",
    "    elif data['room_type'][i]=='Private room':\n",
    "        if data['property_type'][i] == 'Private room in barn' or data['property_type'][i] == 'Private room in loft':\n",
    "            BuildingType.append('Loft')\n",
    "        elif data['property_type'][i] == 'Room in boutique hotel' or data['property_type'][i] == 'Private room in dome house' or data['property_type'][i] == 'Private room in castle' :\n",
    "            BuildingType.append('Boutique Hotel')\n",
    "        elif data['property_type'][i] == 'Private room in townhouse' or data['property_type'][i] == 'Private room in villa':\n",
    "            BuildingType.append('Villa')\n",
    "        elif data['property_type'][i] == 'Private room in kezhan':\n",
    "            BuildingType.append('Kezhan')\n",
    "        elif data['property_type'][i] == 'Room in hotel' or data['property_type'][i] == 'Private room in guest suite' or data['property_type'][i] == 'Private room in guesthouse' or data['property_type'][i] == 'Private room in hostel' or data['property_type'][i] == 'Room in aparthotel':\n",
    "            BuildingType.append('Hotel')\n",
    "        elif data['property_type'][i] == 'Private room in bed and breakfast' or data['property_type'][i] == 'Private room in bungalow' or data['property_type'][i] == 'Private room in casa particular' or data['property_type'][i] == 'Private room in residential home':\n",
    "            BuildingType.append('House')\n",
    "        elif data['property_type'][i] == 'Private room in resort':\n",
    "            BuildingType.append('Resort')\n",
    "        elif data['property_type'][i] == 'Private room in minsu' or data['property_type'][i] == 'Private room in nature lodge' or data['property_type'][i] == 'Private room in yurt' or data['property_type'][i] == 'Private room in tiny house':\n",
    "            BuildingType.append('Homestay')\n",
    "        elif data['property_type'][i] == 'Private room in cottage' or data['property_type'][i] == 'Private room in ranch' or data['property_type'][i] == 'Private room in farm stay':\n",
    "            BuildingType.append('Agritainment')\n",
    "        elif data['property_type'][i] == 'Private room in cabin' or data['property_type'][i] == 'Private room in chalet':\n",
    "            BuildingType.append('Cabin')\n",
    "        elif data['property_type'][i] == 'Private room in tent':\n",
    "            BuildingType.append('Tent')\n",
    "        else:\n",
    "            BuildingType.append('Apartment')\n",
    "\n",
    "\n",
    "    else:\n",
    "        if data['property_type'][i] == 'Shared room in loft' or data['property_type'][i] == 'Shared room in barn':\n",
    "            BuildingType.append('Loft')\n",
    "        elif data['property_type'][i] == 'Shared room in townhouse' or data['property_type'][i] == 'Shared room in villa':\n",
    "            BuildingType.append('Villa')\n",
    "        elif data['property_type'][i] == 'Shared room in kezhan':\n",
    "            BuildingType.append('Kezhan')\n",
    "        elif data['property_type'][i] == 'Shared room in guest suite' or data['property_type'][i] == 'Shared room in guesthouse' or data['property_type'][i] == 'Shared room in hostel' or data['property_type'][i] == 'Shared room in aparthotel' or data['property_type'][i] == 'Shared room in boutique hotel':\n",
    "            BuildingType.append('Hotel')\n",
    "        elif data['property_type'][i] == 'Shared room in bed and breakfast'or data['property_type'][i] == 'Shared room in bungalow' or data['property_type'][i] == 'Shared room in residential home' or data['property_type'][i] == 'Shared room in casa particular':\n",
    "            BuildingType.append('House')\n",
    "        elif data['property_type'][i] == 'Shared room in farm stay':\n",
    "            BuildingType.append('Agritainment')\n",
    "        elif data['property_type'][i] == 'Shared room in tent':\n",
    "            BuildingType.append('Tent')\n",
    "        else: \n",
    "            BuildingType.append('Apartment')\n",
    "        \n",
    "data['property_type'] = BuildingType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=data.drop('Unnamed: 0',axis=1)\n",
    "# data=data.drop('neighborhood_overview',axis=1)\n",
    "# data.to_csv(\"result6.csv\")\n",
    "# import the data\n",
    "data = pd.read_csv('result6.csv', encoding='utf-8')\n",
    "# data.isnull().sum()#判断每一列存在na的数值的数目\n",
    "# 处理bath数据\n",
    "avail = []\n",
    "for i in range(0,len(data['room_type'])):\n",
    "    if data['has_availability'][i]=='f':\n",
    "        avail.append('Not Available')\n",
    "    else:\n",
    "        if data['availability_30'][i] > 0:\n",
    "            avail.append('Available in 30 days')\n",
    "        elif data['availability_30'][i] == 0 and data['availability_60'][i] > 0:\n",
    "            avail.append('Available in 60 days')\n",
    "        elif data['availability_60'][i] == 0 and data['availability_90'][i] > 0:\n",
    "            avail.append('Available in 90 days')\n",
    "        else:\n",
    "            avail.append('Available in 365 days')\n",
    "\n",
    "data['has_availability']= avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"result7.csv\")\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "data=data.drop('availability_30',axis=1)\n",
    "data=data.drop('availability_60',axis=1)\n",
    "data=data.drop('availability_90',axis=1)\n",
    "data=data.drop('availability_365',axis=1)\n",
    "\n",
    "data=data.drop('minimum_minimum_nights',axis=1)\n",
    "data=data.drop('maximum_minimum_nights',axis=1)\n",
    "data=data.drop('minimum_maximum_nights',axis=1)\n",
    "data=data.drop('maximum_maximum_nights',axis=1)\n",
    "data=data.drop('minimum_nights_avg_ntm',axis=1)\n",
    "data=data.drop('maximum_nights_avg_ntm',axis=1)\n",
    "\n",
    "data=data.drop('number_of_reviews_ltm',axis=1)\n",
    "data=data.drop('number_of_reviews_l30d',axis=1)\n",
    "data=data.drop('first_review',axis=1)\n",
    "data=data.drop('last_review',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('result7.csv', encoding='utf-8')\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "for i in range(0,len(data['review_scores_rating'])):\n",
    "    if data['review_scores_rating'][i]== -1:\n",
    "        data['review_scores_accuracy'][i] = 0\n",
    "        data['review_scores_cleanliness'][i] = 0\n",
    "        data['review_scores_checkin'][i] = 0\n",
    "        data['review_scores_communication'][i] = 0\n",
    "        data['review_scores_location'][i] = 0\n",
    "        data['review_scores_value'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('result7.csv', encoding='utf-8')\n",
    "for i in range(len(data)):\n",
    "    if str(data.at[i, 'review_scores_rating']) == 'nan':\n",
    "        data.at[i, 'review_scores_rating'] = -1\n",
    "data.to_csv(\"result8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('result8.csv', encoding='utf-8')\n",
    "data = data[data['review_scores_rating']!=-1]\n",
    "data = data[data['review_scores_rating']!=0]\n",
    "data.to_csv(\"result8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('result8.csv', encoding='utf-8')\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "for i in range(len(data)):\n",
    "    if str(data.at[i, 'review_scores_value']) == 'nan':\n",
    "        data.at[i, 'review_scores_value'] = -1\n",
    "data = data[data['review_scores_value']!=-1]\n",
    "data.to_csv(\"result9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listing_id        0\n",
      "date              0\n",
      "reviewer_id       0\n",
      "reviewer_name    67\n",
      "comments          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('reviews_Shanghai.csv', encoding='utf-8')\n",
    "for i in range(len(data)):\n",
    "    if str(data.at[i, 'comments']) == 'nan':\n",
    "        data.at[i, 'comments'] = 0\n",
    "\n",
    "print(data.isnull().sum()) #判断每一列存在na的数值的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5v/m9by5x3116j60gk92m7lk0vr0000gn/T/ipykernel_35571/3447372174.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcomments_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_contains_chinese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcomments_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSnowNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5v/m9by5x3116j60gk92m7lk0vr0000gn/T/ipykernel_35571/2575929637.py\u001b[0m in \u001b[0;36mis_contains_chinese\u001b[0;34m(strs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#检验是否含有中文字符\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_contains_chinese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_char\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'\\u4e00'\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0m_char\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m'\\u9fa5'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('reviews_Shanghai.csv', encoding='utf-8')\n",
    "# 处理neigh_over\n",
    "comments_value= []\n",
    "for i in range(0,len(data['comments'])):\n",
    "    if data['comments'][i] == 0:\n",
    "        comments_value.append(0)\n",
    "    elif is_contains_chinese(data['comments'][i]):\n",
    "        comments_value.append(SnowNLP(data['comments'][i]).sentiments)\n",
    "    else:\n",
    "        comments_value.append((TextBlob(data['comments'][i]).sentiment.polarity+1)/2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comments']=comments_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            24963\n",
       "1            24963\n",
       "2            24963\n",
       "3            24963\n",
       "4            24963\n",
       "            ...   \n",
       "347263    53884153\n",
       "347264    53884153\n",
       "347265    53897865\n",
       "347266    53909343\n",
       "347267    53926916\n",
       "Name: listing_id, Length: 347268, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[24963]\n",
    "for i in range(1,len(data['listing_id'])):\n",
    "    if data.iloc[i-1,0]!=data.iloc[i,0]:\n",
    "        list.append(data.iloc[i,0])\n",
    "list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "data = pd.read_csv('result7.csv', encoding='utf-8')\n",
    "data2 = pd.read_csv('scores.csv', encoding='utf-8')\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "description = data['description']\n",
    "neiover = data['neiover']\n",
    "\n",
    "checkin = data2['checkin']\n",
    "basic = data2['basic']\n",
    "bath = data2['bath']\n",
    "kitchen = data2['kitchen']\n",
    "security = data2['security']\n",
    "\n",
    "checkin  = preprocessing.minmax_scale(checkin)\n",
    "basic  = preprocessing.minmax_scale(basic)\n",
    "bath  = preprocessing.minmax_scale(bath)\n",
    "kitchen  = preprocessing.minmax_scale(kitchen)\n",
    "security  = preprocessing.minmax_scale(security)\n",
    "\n",
    "data=data.iloc[:,0:39]\n",
    "data.columns\n",
    "\n",
    "data['description'] = description\n",
    "data['neiover'] = neiover\n",
    "\n",
    "data['Checkin'] = checkin\n",
    "data['Basic'] = basic\n",
    "data['Bathroom'] = bath\n",
    "data['Kitchen'] = kitchen\n",
    "data['Security'] = security\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"result9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('result9.csv', encoding='utf-8')\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "for i in range(len(data)):\n",
    "    if str(data.at[i, 'review_scores_rating']) == 'nan':\n",
    "        data.at[i, 'review_scores_rating'] = -1\n",
    "data = data[data['review_scores_rating']!=-1]\n",
    "data = data[data['review_scores_rating']!=0]\n",
    "data.to_csv(\"result10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('result10.csv', encoding='utf-8')\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "for i in range(len(data)):\n",
    "    if str(data.at[i, 'review_scores_value']) == 'nan':\n",
    "        data.at[i, 'review_scores_value'] = -1\n",
    "data = data[data['review_scores_value']!=-1]\n",
    "data.to_csv(\"result11.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
